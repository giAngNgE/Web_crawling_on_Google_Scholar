# Web_crawling_on_Google_Scholar

Google Scholar is a web service that indexes the metadata of research articles on many scientists. Majority of computer scientists choose to use Google scholar to track their publications and research development. Therefore, the web crawling on Google Scholar can provide the citation information on all professors with a public Google Scholar profile.

In 2021, to better introduce all the emeritus professors, professors and associate professors in the school of IT, Deakin university wants to collect all the citation information on them. I am required to implement a web crawler, design and complete the code in the notebook and make sure that the web crawling code meets the requirements. I am free to use any Python package for Web crawling.

1. Data Manipulation

1.1 Professor list generation

I will need to import the suitable web crawling library and use the corresponding library to crawl the School of IT staff list page: https://www.deakin.edu.au/information-technology/staff-listing.

----- Import and install your web crawling library

----- Crawl and Generate the list

1.2 Professor Citation Information generation

----- Professor citation information generation

----- Identify the professor with the most citations

----- Identify the associate professor with the most i10-index since 2016

----- Identify those with the citations-since2016 > 2500

2. Prediction

2.1 A/Professor Gang Li citation Information Extraction

----- Crawl and Generate the citation dataframe

2.2 Train Arima to predict the 2018 to 2020 citation

----- Train Arima Model

----- Predicting the citation and Calculate the RMSE

----- Visualization for comparison

2.3 Parameter selection and 2021-2022 Prediction

----- Grid Search 

----- Select the best parameter values and Predict for 2021 and 2022


## Author
- [@Eden Nguyen](https://github.com/giAngNgE)





